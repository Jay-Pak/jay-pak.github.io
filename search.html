<!DOCTYPE html>
<html>
<head>

    <!-- Document Settings -->
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <!-- Base Meta -->
    <!-- dynamically fixing the title for tag/author pages -->



    <title>Search Result</title>
    <meta name="HandheldFriendly" content="True" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/earlyaccess/nanumgothic.css"/>
    <!-- Styles'n'Scripts -->
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/screen.edited.css" />
    <link rel="stylesheet" type="text/css" href="/assets/built/syntax.css" />
    <!-- highlight.js -->
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css">
    <style>.hljs { background: none; }</style>

    <!-- This tag outputs SEO meta+structured data and other important settings -->
    <meta name="description" content="My Study Space...." />
    <link rel="shortcut icon" href="https://jay-pak.github.io/assets/images/favicon.png" type="image/png" />
    <link rel="canonical" href="https://jay-pak.github.io/search" />
    <meta name="referrer" content="no-referrer-when-downgrade" />

     <!--title below is coming from _includes/dynamic_title-->
    <meta property="og:site_name" content="To Be Continue....." />
    <meta property="og:type" content="website" />
    <meta property="og:title" content="Search Result" />
    <meta property="og:description" content="My Study Space...." />
    <meta property="og:url" content="https://jay-pak.github.io/search" />
    <meta property="og:image" content="https://jay-pak.github.io/assets/images/blog-cover.jpg" />
    <meta property="article:publisher" content="https://www.facebook.com/ITLimited" />
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:title" content="Search Result" />
    <meta name="twitter:description" content="My Study Space...." />
    <meta name="twitter:url" content="https://jay-pak.github.io/" />
    <meta name="twitter:image" content="https://jay-pak.github.io/assets/images/blog-cover.jpg" />
    <meta name="twitter:label1" content="Written by" />
    <meta name="twitter:data1" content="To Be Continue....." />
    <meta name="twitter:site" content="@" />
    <meta name="twitter:creator" content="@" />
    <meta property="og:image:width" content="2000" />
    <meta property="og:image:height" content="666" />

    <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Website",
    "publisher": {
        "@type": "Organization",
        "name": "To Be Continue.....",
        "logo": "https://jay-pak.github.io/"
    },
    "url": "https://jay-pak.github.io/search",
    "image": {
        "@type": "ImageObject",
        "url": "https://jay-pak.github.io/assets/images/blog-cover.jpg",
        "width": 2000,
        "height": 666
    },
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://jay-pak.github.io/search"
    },
    "description": "My Study Space...."
}
    </script>

    <!-- <script type="text/javascript" src="https://demo.ghost.io/public/ghost-sdk.min.js?v=724281a32e"></script>
    <script type="text/javascript">
    ghost.init({
    	clientId: "ghost-frontend",
    	clientSecret: "f84a07a72b17"
    });
    </script> -->

    <meta name="generator" content="Jekyll 3.6.2" />
    <link rel="alternate" type="application/rss+xml" title="Search Result" href="/feed.xml" />


</head>
<body class="page-template">

    <div class="site-wrapper">
        <!-- All the main content gets inserted here, index.hbs, post.hbs, etc -->
        <!-- < default -->
<!-- The tag above means: insert everything in this file
into the {body} of the default.hbs template -->

<!-- The big featured header, it uses blog cover image as a BG if available -->
<header class="site-header outer">
    <div class="inner">
        <nav class="site-nav">
    <div class="site-nav-left">
        
            
                <a class="site-nav-logo" href="https://jay-pak.github.io/">To Be Continue.....</a>
            
        
        
            <ul class="nav" role="menu">
    <li class="nav-home" role="menuitem"><a href="/">Home</a></li>
    <li class="nav-about" role="menuitem"><a href="/about/">About</a></li>
    <li class="nav-getting-started" role="menuitem"><a href="/tag/getting-started/">Getting Started</a></li>
    <li class="nav-getting-started" role="menuitem"><a href="/tag/g-suite/">G Suite</a></li>
    <li class="nav-IaaS" role="menuitem"><a href="/tag/infrastructure/">Infrastructure</a></li>
    <li class="nav-bigquery" role="menuitem"><a href="/tag/bigdata/">Big Data</a></li>
</ul>

        
    </div>
    <div class="site-nav-right">
        <div class="social-links">
            
                <a class="social-link social-link-fb" href="https://facebook.com/ITLimited" target="_blank" rel="noopener"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 32"><path d="M19 6h5V0h-5c-3.86 0-7 3.14-7 7v3H8v6h4v16h6V16h5l1-6h-6V7c0-.542.458-1 1-1z"/></svg>
</a>
            
            
        </div>
        
            <a class="subscribe-button" href="#subscribe">Search</a>
        
    </div>
</nav>

    </div>
</header>

<!-- Everything inside the #post tags pulls data from the post -->
<!-- #post -->

<main id="site-main" class="site-main outer" role="main">
    <div class="inner">

        <article class="post-full post page no-image">

            <header class="post-full-header">
                <h1 class="post-full-title">Search Result</h1>
            </header>

            

            <section class="post-full-content">
                <!-- 
<form action="/search" method="get" hidden="hidden">
    <label for="search-box"></label>
    <input type="text" id="search-box" name="query">
</form>

<ul class="mylist" id="search-results"></ul>

<script>
    window.store = {
    
    "compute-engine-docker": {
        "title": "Linux에 Docker 설치 하기 (With Google Cloud Compute Engine) - 1",
            "author": "compute-engine",
            "category": "",
            "content": "Linux Docker 설치하기 ( With Google Cloud Compute Engine) - 1사실 나는 개발쪽을 손을 놓은지 거의 5년이 되어 간다. 하지만 Cloud에 발을 들인 이상 개발쪽을 등한시 할 수 없어 다시 개발을 해보려고 한다. 사실 Data Engineering 일 혹은 Data Architect를 하면서 Meta Data를 수집 하기 위한 Thread Base의 Java Application을 간혹 개발을 했지만, Web Application에 대해 손을 놓은건 거의 5년이 넘어 가는 거 같다. 5년의 세월 동안 많은 변화가 있는거 같다. 솔직히 무슨 말을 하는지도 모르겠다. Cloud를 하게 되며, 이제는 개발을 등한시 해서는 Data 분석에 대한 시야가 슬슬 좁아진다는 생각이 들기 시작 했다. 모든 데이터 분석이나 혹은 Machine Learning의 시작은 양질의 데이터의 수집에서 시작된다는 것을 잠시 잊고 살았던거 같다. 자조 적인 개소리(?)는 여기서 집어 치우고, 다시 개발을 하기 위한 시작을 위해 우선 환경부터 만들어 보고자 한다. 사실 Kubernetes를 사용 할 수 있지만 Kubernetes를 사용 해보기 앞서 일단 Docker의 기초를 다지고자 Docker 위에 Nginx와 Tomcat부터 해보기로 했다.Compute Engine Instance 만들기Compute Engine instance 만들기는 전에 Posting 한 Compute Engine 만들기 를 참조하기 바란다. 이때 주의 할점은 http 트래픽 허용과 https 트래픽을 허용 하도록 한다.Docker 설치Docker는 Windows나 Linux에서 설치 가능하다. 여기서는 Linux에서 설치 하도록 한다. 설치를 위해 아래 Script를 실행한다.sudo apt-get update sudo apt-get upgradesudo curl -fsSL https://get.docker.com/ | sudo sh위 Script를 실행 하면 Docker의 설치가 시작 된다. Docker는 Root 계정 위에서 실행이 가능 하기 때문에 좀더 편리한 사용을 위해 아래 Script를 실행 한다.sudo usermod -aG docker $USER위 Script를 추가 후 ssh를 shell을 다시 열어 보면 sudo를 제외 하고 docker를 이용할 수 있다.이제 Docker가 설치 되었다. 아래 명령으로 Docker가 제대로 설치 되었는지 확인을 해보면 된다.docker versionDocker Image 얻기이제 Docker가 설치 되었으니, Docker Container를 얻어야 한다. Docker는 Docker Hub에서 Image를 얻거나  DockerFile을 이용하여, Docker Image를 생성할 수도 있다. 여기서는 Docker hub에서 얻도록 한다.Docker Image 검색우선 아래 명령으로 Docker hub에 존재하는 Docker Image의 List를 보도록 한다.docker search tomcat위 명령을 실행 하면 아래와 같이 Docker Hub에 존재하는 Docker Image의 List를 얻을 수 있다. 이때 star 를 보면 사람들이 추천하는 횟수를 볼 수 있다. 이를 기준으로 어떤 Image를 이용하면 된다.            [Fig. 1 - Docker Hub Search]찾고자 하는 Docker Image를 찾았다면, 아래 Script로 Docker Image를 얻도록 한다.docker pull [Image Name]우리는 tomcat을 설치 할 것이므로, tomcat의 이미지를 얻도록 한다.            [Fig. 2 - Docker Image를 얻는다.]위에서 docker pull tomcat:8에서 tomcat:8 을 주목 하면, tomcat의 Image 중 뒤에 Tag 된 Tomcat의 Version이 설치된 image를 얻을 수 있다.  예를 들어 Tomcat 6 Version을 얻고 싶다면 아래와 같이 얻도록 한다. 다른 Image의 Tag 내용을 알고 싶다면 Docker Hub를 참조하기 바란다.            [Fig. 3 - 다른 버젼의 Tomcat Image를 얻기]여기서는 최신 버젼인 latest 를 사용하도록 한다. 아래와 같이 받은 docker image를 삭제 하도록 한다.            [Fig. 4 - Docker Image 삭제 하기]이제 Image를 얻었으니 Docker얻은 이미지로 Docker를 실행 하도록 한다.docker run -d tomcat:latest            [Fig. 5 - Docker 실행 하기]위와 같이 docker Container가 실행 된것을 볼 수 있다. 이제 제대로 실행 되었는가를 확인 해보면 된다. 우선 Container의 IPAddress를 얻도록 한다.docker inspect [Container ID] | grep IPAddress위와 같이 실행하면 아래와 같은 결과를 얻을 수 있다.            [Fig. 6 - IP Address 얻기]이후 Browser에서 확인을 해봤으면 좋겠지만.. 아직은 아니다. 좀 참도록 하자. 우선 curl 명령으로 test를 한다.            [Fig. 7 - curl test하기]정상적으로 돌아 가고 있는것으로 보인다. 이제는 자신의 노트북으로 고양이를 보고 싶을 것이다. 그렇게 하기 위해서는 우선적으로 조건이 있다.  방화벽 규칙 설정 하기  Compute engine Network Tag Update지금 부터 순차적으로 적용 해보록 한다. Main 화면의  &lt;img src=”../assets/images/top-menu.png” width=30px height=30px/&gt;를 클릭 해서 네트워킹 - VPC 네트워크 - 방화벽 규칙 Menu를 클릭 하도록 한다.            [Fig. 7 - 방화벽 규칙]            [Fig. 7-1 - 방화벽 규칙 설정하기]여기서 대상 태그의 이름을 기억해 뒀다가 아래와 같이 Compute engine Network Tag에 추가하도록 한다.            [Fig. 7-2 - Compute engine Config 변경]그리고 몇분 후 http://[External IP]:8080을 이용하여 Test해보도록 한다.            [Fig. 7-3 - Tomcat Test]다음은 nginx + Tomcat을 연동하는 것을 Posting을 해보도록 하겠다.",
        "url": "/Compute-engine-docker"
    }
    ,
    
    "google-cloud-plarform-join": {
        "title": "Google Cloud Platform 가입하기",
            "author": "google-cloud",
            "category": "",
            "content": "Google Cloud의 Service를 이용하기 위해서는 Google Cloud Platform Console에 접속하여 사용 하면 되는데, Console에 접속 하기 위해서는 Google Cloud Platform에 가입절차를 거쳐야 한다. 가입을 위해서는 Gmail계정이나 Google의 Business SaaS(Service as a Service) Service인 G Suite서비스를 이용중 인 Mail계정이 필요하다. 이와는 별도로 계정에 연결할 신용카드가 필요한데, 해외 결제 가능 카드(VISA, Master, Union Pay etc..)면 사용 가능하다.Google은 가입하는 순간 300$의 무료 Credit을 12개월 동안 사용 가능 하도록 제공한다. 그리고, 300$의 Credit을 전부 사용 했거나, 12개월의 기간이 끝난다 하더라도 자동으로 과금이 되지 않고, 가입한 계정의 업그레이드를 해야지만 과금이 시작되므로, 잠시 Test를 위해 계정을 만들어서 신용카드를 연결 한다고 해서 사용료를 지불할 걱정은 하지 않아도 된다.Google Cloud Platform 가입하기우선 가입하기 위해 위에 언급 했던 Google Cloud Platform Console(Https://console.cloud.google.com)로 접속 한다.Google Cloud Platform에 처음 접속하게 되면 아래와 같은 Login 화면이 나오게 된다. 이때, Gmail계정이나, G Suite으로 생성된 Mail계정을 입력 하도록 한다. 지금 입력 계정은 회사에서 Demo로 사용중인 G suite 계정이다.            [Fig. 1 - Google Cloud Platform Login]Login에 성공하게 되면 아래와 같이 Welcome 화면이 나오며, Product에 대한 Update소식이나 Marketing에 대해 Mail로 받는 것에 동의여부를 묻는 화면이 나오는데 Marketing은 동의 하지 않아도 되지만 아래는 서비스 사용에 대한 동의를 묻는 것이기 때문에 동의를 하도록 한다.            [Fig. 2 - Google Cloud Platform Login]위 절차를 끝내게 되면 아래와 같이 화면이 나오는데 이는 가입은 되었지만, Google Cloud Platform의 사용을 위한 활성화가 되지 않은 상태이다. 활성화를 위해 맨 위 오른쪽의 활성화 버튼이나, 아래 빨간 박스의 무료로 사용해 보기버튼을 클릭한다.            [Fig. 3 - Google Cloud Platform 가입되었으나 활성화 되지 않은 상태]이제 활성화를 위해 아래 화면과 같이 동의 화면이 나오는데 앞서 Fig 2에 한 것 과 같이 설정하고 맨 아래 동의 및 계속하기를 클릭한다.            [Fig. 4 - 활성화 단계 - 동의]동의 화면 이후 개인 정보와 결제 정보를 입력 한다.            [Fig. 5 - 활성화 단계 - 사용자 정보 및 결제정보 1]            [Fig. 6 - 활성화 단계 - 사용자 정보 및 결제정보 2]위에서 말했다 시피 결제 정보를 입력 했다 하더라도, 무료계정에서 업그래이드를 하지 않는 이상 결제가 되지 않는다. 다만, 카드의 유효성을 검사 하기 위해 1$ 결제되고 난후, 결제 취소가 될 수 있다.이번 Post에서는 Google Cloud를 이용하기 위한 가입 절차를 살펴 보았다. 다음은 Google Cloud를 이용하기 위한 Google Cloud SDK를 설치 하는 방법에 대해 알아보도록 하겠다.",
        "url": "/Google-Cloud-Plarform-Join"
    }
    ,
    
    "google-cloud-compute-engine-usage-2": {
        "title": "Google Cloud Compute Engine (2) - Compute Engine Instance 생성",
            "author": "compute-engine",
            "category": "",
            "content": "  Google Cloud Compute Engine (1) - Project 생성하기  Google Cloud Compute Engine (2) - Compute Engine Instance 생성이번 Post에서는 Google Cloud의 자원 중 Compute Engine을 사용하는 방법에 대해 알아 보도록 하겠다. Google Cloud Compute Engine(GCE)은 Google Cloud 내에 가상 머신(Virtual Machine=VM)으로 Google Cloud의 IaaS(Infrastructure as a Service)이다. Compute Engine을 이용하면, Google의 Peta byte급의 Network 및 Persistant Disk 등의 자원을 저렴하게 이용할 수 있고, 높은 수준의 SLA(Service Level Agreement)를 보장한다.Google Cloud의 Compute Engine Instance를 생성 하는 방법에는 2가지 방법이 있다.하나는, Google Cloud Web Console에서 생성하는 방법과 다른 하나는 앞서 설치 한 Cloud SDK를 이용한 방법이 있다. 그에 앞서 Project의 생성에 대해 먼저 알아 보도록 한다.1. Project 생성 (Optional)아래와 같이 Google Cloud Web Console로 접속 한다. 만약, Google Cloud Platform의 계정을 처음 활성화 한 상태라면, My First Project라는 Project 명이 보일 것이다. Test를 위해 간단히 할 것이라면, 처음 생성된 Project를 이용해도 무방하다. 그렇지 않고 신규로 생성하고 싶은 경우 아래와 같이 신규로 Project를 생성하도록 한다.Google Cloud Platform의 구조는 아래와 같은 구조로 이루어져있으며, 개인 사용자의 경우 간단히 Account 아래 여러 Project가 Sub로 붙어 있는 구조이다. 우선 아래 그림 [Fig 1.1]에서 처럼 Project를 Click하면 그림[Fig 1.2]의 프로젝트 생성을 위한 화면을 볼 수 있다.    \t    [Fig 1-1. Google Cloud Console Project 선택]    \t    [Fig 1-2. Project 생성] 다른 방법으로는 그림 [Fig 2-1]에서 처럼 옆 &lt;img src=”../assets/images/top-menu.png” width=30px height=30px/&gt;를 클릭 해서 IAM 및 관리자 - 리소스 관리 Menu를 클릭 하도록 한다.    \t    [Fig 2-1. Menu에서 리소스 관리 선택]    \t    [Fig 2-2. 리소스 관리에서 Project 만들기 선택]    \t    [Fig 2-3. Project 생성]Project 생성 시 Project 이름은 중복이 가능 하나, 아래 작은 글씨로 자동 생성된 Project ID는 다른 Google Cloud 내에 다른 Project들과 중복이 되면 안된다. 그리고, Project ID는 향후 변경 할 수 없으므로, 대규모 Project에서 여러 Project를 연결 할 경우 Naming Rule을 결정 할 필요가 있다. 이는 다음에 자세히 살펴보도록 한다.이번에는 Project 생성에 대해 알아 보았다. 전사(Enterprise)의 시각으로 보자면 Project의 생성은 곧 하나의 조직이 될수 있고, 이는 논리적인 하나의 업무 혹은 조직이 될 수 있으며, 조직의 구조는 Cloud에 있는 Landscape의 구조로 볼 수 있을 것이다. 때문에, Project의 구조를 잡는것은 관리적인 측면에서 아주 중요한 부분이 될 수 있을 것이고, 효율적인 IT 운영의 첫걸음이 될 수 있을 것이다.아직은 Cloud의 경험이 적어 이런 부분에 대한 포스팅을 하긴 어렵다. 이런 부분은 Project의 경험이 많이 필요하기 때문에, 향후 나중에 포스팅 할 기회가 있으면 해보도록 하려고 한다.다음은 본격적으로 Google Cloud Compute Engine의 생성/삭제에 대해 알아보도록 하겠다.",
        "url": "/Google-Cloud-Compute-Engine-Usage-2"
    }
    ,
    
    "google-cloud-compute-engine-usage-1": {
        "title": "Google Cloud Compute Engine (1) - Project 생성하기",
            "author": "compute-engine",
            "category": "",
            "content": "  Google Cloud Compute Engine (1) - Project 생성하기  Google Cloud Compute Engine (2) - Compute Engine Instance 생성이번 Post에서는 Google Cloud의 자원 중 Compute Engine을 사용하는 방법에 대해 알아 보도록 하겠다. Google Cloud Compute Engine(GCE)은 Google Cloud 내에 가상 머신(Virtual Machine=VM)으로 Google Cloud의 IaaS(Infrastructure as a Service)이다. Compute Engine을 이용하면, Google의 Peta byte급의 Network 및 Persistant Disk 등의 자원을 저렴하게 이용할 수 있고, 높은 수준의 SLA(Service Level Agreement)를 보장한다.Google Cloud의 Compute Engine Instance를 생성 하는 방법에는 2가지 방법이 있다.하나는, Google Cloud Web Console에서 생성하는 방법과 다른 하나는 앞서 설치 한 Cloud SDK를 이용한 방법이 있다. 그에 앞서 Project의 생성에 대해 먼저 알아 보도록 한다.Project 생성 (Optional)아래와 같이 Google Cloud Web Console로 접속 한다. 만약, Google Cloud Platform의 계정을 처음 활성화 한 상태라면, My First Project라는 Project 명이 보일 것이다. Test를 위해 간단히 할 것이라면, 처음 생성된 Project를 이용해도 무방하다. 그렇지 않고 신규로 생성하고 싶은 경우 아래와 같이 신규로 Project를 생성하도록 한다.Google Cloud Platform의 구조는 아래와 같은 구조로 이루어져있으며, 개인 사용자의 경우 간단히 Account 아래 여러 Project가 Sub로 붙어 있는 구조이다. 우선 아래 그림 [Fig 1.1]에서 처럼 Project를 Click하면 그림[Fig 1.2]의 프로젝트 생성을 위한 화면을 볼 수 있다.    \t    [Fig 1-1. Google Cloud Console Project 선택]    \t    [Fig 1-2. Project 생성] 다른 방법으로는 그림 [Fig 2-1]에서 처럼 옆 &lt;img src=”../assets/images/top-menu.png” width=30px height=30px/&gt;를 클릭 해서 IAM 및 관리자 - 리소스 관리 Menu를 클릭 하도록 한다.    \t    [Fig 2-1. Menu에서 리소스 관리 선택]    \t    [Fig 2-2. 리소스 관리에서 Project 만들기 선택]    \t    [Fig 2-3. Project 생성]Project 생성 시 Project 이름은 중복이 가능 하나, 아래 작은 글씨로 자동 생성된 Project ID는 다른 Google Cloud 내에 다른 Project들과 중복이 되면 안된다. 그리고, Project ID는 향후 변경 할 수 없으므로, 대규모 Project에서 여러 Project를 연결 할 경우 Naming Rule을 결정 할 필요가 있다. 이는 다음에 자세히 살펴보도록 한다.이번에는 Project 생성에 대해 알아 보았다. 전사(Enterprise)의 시각으로 보자면 Project의 생성은 곧 하나의 조직이 될수 있고, 이는 논리적인 하나의 업무 혹은 조직이 될 수 있으며, 조직의 구조는 Cloud에 있는 Landscape의 구조로 볼 수 있을 것이다. 때문에, Project의 구조를 잡는것은 관리적인 측면에서 아주 중요한 부분이 될 수 있을 것이고, 효율적인 IT 운영의 첫걸음이 될 수 있을 것이다.아직은 Cloud의 경험이 적어 이런 부분에 대한 포스팅을 하긴 어렵다. 이런 부분은 Project의 경험이 많이 필요하기 때문에, 향후 나중에 포스팅 할 기회가 있으면 해보도록 하려고 한다.다음은 본격적으로 Google Cloud Compute Engine의 생성/삭제에 대해 알아보도록 하겠다.",
        "url": "/Google-Cloud-Compute-Engine-Usage-1"
    }
    ,
    
    "google-cloud-sdk-install": {
        "title": "Google Cloud SDK Install",
            "author": "google-cloud",
            "category": "",
            "content": "Google Cloud는 Cloud위의 Resource를 관리할 수 있는 2가지 도구를 제공한다. 하나는 Cloud Web Console이고, 또 다른 하나는 CLI(Command Line Interface : 명령표시줄)로 관리할 수있는 Cloud SDK가 그것이다. 뿐만아니라 Google은 Cloud 위의 자원을 관리하기 편하도록 RestAPI를 이용한 도구를 제공하여 자원의 Deploy를 Automation 할 수 있도록 Library를 제공한다. (Java 혹은 PIP, NodeJS etc.). Cloud SDK는 Cloud Resource를 관리 함에 있어 편리하고 빠르게 관리 할 수 있는 방법을 제공한다.여기서는 Cloud SDK를 설치하는 방법에 대해 설명한다.1. PrerequireGoogle Cloud SDK는 Python으로 Programing되어 있으며, 모든 Environment에 Python이 설치 되어 있다는 것을 가정한다. 아래 명령으로 Python이 설치 되어 있는가를 확인 하도록 한다.python --versionpython3 --version         \tFig. 1 - Python Version 확인2. InstallationWindows      Google Cloud SDK Installer를 Download 받는다.        Installer의 Guide에 따라 설치를 진행한다.        명령 Prompt를 실행하여, 아래와 같이 실행하여, 설치 여부를 확인한다.    gcloud --version      Linux / Mac OSXWindows와 같이 Download 받아서 진행 할 수 있지만, 여기에서는 curl을 이용하여 Download부터 설치까지 진행 해보도록 한다.Terminal을 열어 아래와 같이 명령을 실행 하여 본다.$ curl https://sdk.cloud.google.com | bash    \t    Fig. 2 - Cloud SDK 설치  설치 진행 후 아래와 같이 Cloud SDK Bug report를 보내겠냐는 내용이 나오는데, Y를 입력 하고, Google Cloud SDK설치를 진행 하도록 한다.    \t    Fig. 3 - Bug Report 동의 여부  해당 과정이 지나면, 본격적으로 Google Cloud SDK 설치 및 Update가 진행 된다.    \t    Fig. 4 - 설치 진행  이때 설치 및 Update이후 환경 변수 PATH에 추가 하겠냐는 Prompt가 나오는데 이때 Y를 입력 해서 Path에 추가 해주도록 한다. 그렇지 않으면 Cloud SDK를 실행 할때 마다 Terminal에서 해당 경로로 이동하여, 실행 해야하는 불편함이 있다.    \t    Fig. 5 - 환경 변수 추가  이 과정 까지 끝나면 gcloud –version을 입력 하여 제대로 설치 되었음을 확인 한다. 하지만 바로 실행 되지는 않는다. 앞서 말했다시피 Cloud SDK 설치 이후 환경 변수에 등록은 되었으나 바로 실행 되지는 않는다. 바로 실행을 하고 싶다면 아래 와 같이 진행 하면 바로 gcloud 명령을 확인 할수 있다.    \t    Fig. 6 - 설치 확인이렇게 Cloud SDK 설치가 완료 되었다. 다음은 Cloud SDK를 사용한 Cloud 자원을 이용하는 방법에 대해 하나하나 해보도록 하겠다.",
        "url": "/Google-Cloud-SDK-Install"
    }
    ,
    
    "big-query-ml-use-1": {
        "title": "Big Query ML 사용해 보기 (1)",
            "author": "bigquery",
            "category": "",
            "content": "  1. Big Query ML 사용해보기 (1) - Understanding Data(Business)이번 포스트에서는 Binary logistics Regressor를 이용한 Classification Model을 BigQuery ML을 이용하여 만들어 보고자 한다.앞서 이야기한대로 BigQuery ML은 Linear Regression(선형 회귀), Binary logistic regression(이진 로지스틱 회귀)의 모델을 생성 할 수 있다. Linear Regressor는 수치를 예측 하고자 할 때, Binary logistics regression은 분류 예측을 하고자 할때 사용한다.이번 Post는 BigQuery ML에 앞서 분석에 필요한 데이터를 탐색하는 것을 포스팅 해보도록 하겠다.데이터 탐색 및 데이터 이해하기 (Understanding Business)우선 Machine Learning을 위해서는 데이터에 대한 이해 및 탐색. 그리고, 예측을 위해 필요한 데이터의 특성은 무엇인가에 대한 이해가 선행 되어야 한다. 아래 예제에서 사용하는  data-to-insights.ecommerce.web_analytics 는 BigQuery ML을 Test 하기 위해 Merchandise Store의 데이터를 공개한 것이다.1. 방문자 대비 구매자우선 데이터의 이해를 위해 전체 방문자 대비 구매자의 비율을 구하는 쿼리를 수행 해보도록 한다.   #standardSQL WITH visitors AS( SELECT COUNT(DISTINCT fullVisitorId) AS total_visitors FROM `data-to-insights.ecommerce.web_analytics` ), purchasers AS( SELECT COUNT(DISTINCT fullVisitorId) AS total_purchasers FROM `data-to-insights.ecommerce.web_analytics` WHERE totals.transactions IS NOT NULL ) SELECT  total_visitors,  total_purchasers,  total_purchasers / total_visitors AS conversion_rate FROM visitors, purchasers  위의 데이터는 전체 방문자 대비 실제 구매자를 구하는 데이터이다. 위의 with절의 visitor는 방문자의 ID를 Count 하는 데이터이고, purchasers는 전체 데이터중 Transaction Flag가 있는 경우를 거래가 이루어진 것으로 보고, Count 한 데이터이다.      \t    &lt; Fig. 1 - 방문자 대비 실제 구매자 &gt;전체 방문자 수는 741,721명이며(이는 전체 방문 횟수가 아닌 전체 방문자의 수이다.) 이 방문자들 중 실제 구매 한 사람의 수는 20015명이다. 즉 2.69%의 방문자가 Login 후 구매를 진행 하는 것을 알 수 있다.2. 매출과 수익 탐색앞서 방문자와 실제 구매자를 알아 보았다. 하지만, 이것 만으로는 정보가 충분하지 않다. 방문자가 방문해서 구매를 했다 한들, 어떤 어떤 방문자가 어떤 카테고리의 제품을 찾았고, 어떤 제품을 구매 하였는가에 대한 탐색이 필요하다. 아래의 쿼리를 실행 해보자.  #standardSQLSelect prod_name  , prod_cat_name  , Format(\"%'d\",CAST(units_sold AS int64))   as unit_sold  , Format(\"%'.2f\",CAST(revenue AS float64))  as revenue  From (        SELECT          p.v2ProductName prod_name,          p.v2ProductCategory prod_cat_name,          SUM(p.productQuantity) AS units_sold,          ROUND(SUM(p.localProductRevenue/1000000),2) AS revenue        FROM `data-to-insights.ecommerce.web_analytics`,        UNNEST(hits) AS h,        UNNEST(h.product) AS p        GROUP BY 1, 2        ORDER BY revenue DESC        LIMIT 5);        \t    &lt; Fig. 2 - 매출 상위 5개 제품 &gt;      위 Query는 전체 매출 중 가장 많이 팔린 상품 명과 수량에 대해, 상위 5개를 보여주는 쿼리이다.이때, From 절의 Inline View 쿼리 중 UNNEST(hits), UNNEST(h.product)를 볼 수 있는데, 이는 해당 Table의 Denormalize 된 테이블의 Reapeat Column을 사용하는 것이고, Target Table의 Dataset의 1개의 Row에 대응되는 Repeat 컬럼에 대해 배열로 나열 하여, 연산 하는데 사용하려는 것이다. 다시 말해 Unnest Keyword는 Denormalize 된 Table의 Row에 대해 하나의 배열 타입으로 바꿔서 하나의 테이블로 인식 하는 역할을 해주는 것이다. 즉, Query 상에서 Table의 Row에 대해 1:N의 형태로 풀어 주는 역할을 한다.  3. 정리우리는 지금까지 간단하게 나마, Google의 Merchandise Store의 Data를 가지고 방문자와 실제 구매자, 그리고 매출 상위 5개의 제품에 대해 탐색 해보았다. 이것으로 이해 할지는 모르겠지만, 위에서 보는 것 처럼 데이터를 이해 하는 것은 Business를 이해 하는 것과 같다고 볼수 있을 것이다.가령, 위의 Dataset으로 방문자가 Site에 접속 하여 구매로 이어 지는 Pattern에 대해 분석을 하고 싶다고 가정을 하자. 접속하여 구매까지 이어지는 Pattern을 알기 위해서는 우선 사용자가 접속하는 경로부터 시작 해서 사용자가 검색한 검색어와 검색해서 나온 결과를 가지고 클릭한 제품의 종류, 그리고 제품을 구매하는데 제품에 대한 설명이 명시된 Page에 머문 시간 등, 여러 Factor를 가지고 고객의 구매 Pattern을 분석을 할 수 있을 것이다.하지만, 지금까지의 과정은 과거의 방문자수, 실제 구매자, 매출을 간단히 알아 본것에 불과 하며, 이를 분석 하기 위해서는 더 많은 데이터를 탐색 해야 하며, 실제 인입(Data Ingestion)된 데이터를 단계별로 분석 할 필요가 있고, 이는 반복적이고 많은 데이터를 필요로 할 것이다.Bigquery는 많은 데이터를 쌓기 좋은 대안이 될 것이고, 그 안에서 BigQuery ML은 데이터를 분석하기 위한 반복적인 작업을 획기적으로 줄여 줄것으로 기대 된다.다음은 BigQuery ML을 이용하여, 기존 단면적으로 보이는 데이터를 어떻게 통합하고, Machine Learning모델을 만드는지를 포스팅 해보도록 하겠다.",
        "url": "/Big-Query-ML-Use-(1)"
    }
    ,
    
    "google-cloud-democratization-of-machine-learning-bigquery-ml": {
        "title": "Bigquery ML - BigQuery에서 Machine Learning을..",
            "author": "bigquery",
            "category": "",
            "content": "        \tGoogle NextBigQuery ML은 말 그대로 Big Query 내에서 Machine Learning Model을 생성 할 수 있는 서비스이다. 기업의 데이터 분석가들은 데이터를 활용한 분석 및 예측을 위해서는 R, Python 등 언어를 습득해야 하고, 데이터에 대한 이해도가 높은 사람만이 할 수 있어, 소수 인원의 전유물 처럼 여겨 졌다.이에 Google은 개발 언어를 배우지 않고도, 쉽게 Machine Learning Model을 생성 할 수 있도록 SQL만으로 데이터를 분석 할수 있는 Platform인 BigQuery에 Machine Learning Model을 생성 할 수 있도록 서비스하기 시작하였다. 이와는 별도로, Cloud Auto ML을 발표 하였는데, Cloud AutoML은 인식 시스템의 기계 학습 / AI를 사용한 사용자 정의 기계 학습 모델 구축을 On-Premise에서 실행할 수 있도록하고있다. Cloud AutoML은 이미지 내의 물체 인식 / 분류뿐만 아니라 문서의 분류, 번역에 대응 했다.아래는 BigQuery ML의 Model 생성 및 이를 이용한 예측을 하는 방법을 간단히 설명하는 Image이다.        \t[ 출처 : Google Cloud Big Query ML Documentation ]1. Create Support Model      Linear Regression - 연속성을 가지는 수치 데이터에 대해 예측을 위한 모델.        Binary Logistics Regression - 쉽게 말해 Classification. A인가? B인가? 혹은 어느 군집에 속하는가를 판별 하는 모델.  2. Quota 및 Limitation &amp; Pricing  BigQuery ML은 Machine Learning을 위한 Model을 생성하는데 쓰이는 Query에 대한 Quota를 따른다. Create Model에 대한 Quota는 없다. 자세한 내용은 Big Query Quotas and Limits에서 확인 바란다.3. 사용 가능 환경      BigQuery UI        bq CLI Tool        Big Query Rest API        Jupyter Notebook 또는 BI Platform과 같은 외부 플랫폼  다음 포스팅은 Big Query ML을 간단히 사용해보는 포스팅을 해보고자 한다.",
        "url": "/Google-Cloud-Democratization-of-Machine-Learning-Bigquery-ML"
    }
    ,
    
    "bigquery-ml-training-1": {
        "title": "Big Query ML 뜯어보기",
            "author": "bigquery",
            "category": "",
            "content": "이번 포스트는 Big Query ML을 뜯어 보고자 한다.Bigquery ML을 위해서는 아래와 같이 2가지 Step을 거친다.1. Model Creation (모델 생성)  Bigquery ML의 모델을 생성 하는 것은 익히 알고 있는 Create 구문과 비슷하며, Model 생성에 필요한 Option Parameter는 {Key = Value}의 형태로 사용하면 된다.  [ CREATE MODEL | CREATE MODEL IF NOT EXISTS  | CREATE OR REPLACE MODEL ] model_name       OPTIONS(\t[Options..])AS [SQL_Statement]    Options            NAME      VALUE      Details      Example                  model_type      linear_reglogistic_reg      ‘linear_reg’는 linear regression model을 생성하는데 사용하는 Option이고, ‘logistic_reg’ logistic regression model을 생성하는데 사용한다.해당 Option은 필수로 입력 해야 한다.      model_type=‘linear_reg’model_type=‘logistic_reg’              input_label_cols      STRING      학습에 이용되는 Label 컬럼의 이름을 배열로 열거 한다. 배열이라 해도 하나의 컬럼일 경우 하나의 Label 컬럼을 명시 할 수 있다. 만약, 이 Option이 지정되지 않은 경우 Query 하는 Dataset 컬럼 명 중, “label”이라는 이름이 된 컬럼의 경우 이것을 하나의 input_label로 인식한다. 그 마저 없다면, 모델 생성은 실패한다. Linear Regression 모델의 Label column은 실제 수치 Measure 값(숫자값)으로 하고, Logistics Regression의 경우 Cardinality가 낮은 컬럼을 대상으로 설정 하도록 한다.      inupt_label_cols=[‘col1’,’col2’]              l1_reg      FLOAT64      Model의 L1 정규화를 진행. 여기서 말하는 정규화는 Model의 가중치를  조절 하여, 모델 접합성을 향상 시킨다. 기본값은 0.      l1_reg=0              l2_reg      FLOAT64      Model의 L2 정규화를 진행. 여기서 말하는 정규화는 Model의 가중치를  조절 하여, 모델 접합성을 향상 시킨다. 기본값은 0.      l2_reg=0              max_iterations      INT64      최대 반복 학습 횟수 기본값은 20      max_iterations=20              learn_rate_strategy      line_searchconstant      Training 동안 특정 Learning rate(학습률)를 선정함에 있어, 전략을 선택한다. 2가지 Option을 선택할 수 있다. 기본 값은 ‘line_search’line_search Option은 학습 속도를 늦추고 처리되는 바이트 수를 늘리지 만, 지정된 초기 학습 속도가 더 높더라도 일반적으로 수렴된다는 점에서 트레이드 오프가 될 수 있다. 이 때 learn_rate_stretegy Option에 대해 설정 하지 않거나 line_search일 경우, is_init_learn_rate값을 통해 ml.learn_info에 나타나는 learn_rate의 값을 두배로 설정 하길 Recommand 한다. 최적의 초기 learning rate는 모델 마다 다르므로, 이점을 확일 할 필요가 있다.      learn_rate_strategy=‘line_search’learn_rate_strategy=‘constant’              learn_rate      FLOAT64      learn_rate_strategy Option이 constant일 경우 경사 하강법(gradient descent)의 learning rate를 설정 한다. 만약, learn_rate_strategy의 Option이 line_search일 경우 오류를 return 한다. 기본 값은 0.1이다. learn_rate_strategy가 ‘constant’일 경우 에만 사용하는 Option이다.      learn_rate=0.1              early_stop      BOOL      relative loss improvement(상대적 손실 개선)이 min_rel_progress 미만인 첫 번째 반복 이후에 학습이 중지되어야 함을 나타낸다. 기본값은 ture      early_stop=ture              min_rel_progress      FLOAT64      The minimum relative loss improvement necessary to continue training when early_stop is set to true. For example, a value of 0.01 specifies that each iteration must reduce the loss by 1% for training to continue. The default value is 0.01.                     data_split_method      auto_splitrandomcustomseqno_split      입력 데이터에 대해 Training과 Evaluation dataset을 나누는 방법에 대해 나타낸다. 여기서 Training data는 Model을 학습(training)시키는 데이터를 나타내고, Evaluation Data set은 training 이 후 early stop 시 overfitting을 피하기 위해 Training Model의 검증의 용도로 사용된다. 기본값은 auto_split이다. auto_split : Training data와 Evaluation data를 자동으로 분할 해주는 Option이다. random : 말 그대로 Dataset을 임의적으로 나눈다. (다른 Training을 실시 하면, 서로 다른 Split 결과가 나타난다.)custom : BOOL이란 이름으로 사용자가 컬럼을 만들어 Training Data와 Evaluation Data를 분할 한다. 여기서 컬럼의 값이 ‘true’일 경우 evaluation data로 사용하고 ‘false’일 경우 training data로 사용 한다. seq : 사용자가 제공한 Column을 순차적으로 나눈다. 이때 순차적으로 사용 할 수 있는 Column은 NUMERIC, STRING, TIMESTAMP이다. 나머지 Row는(Null을 포함한 모든 값)은 Evaluation data로 활용된다. no_split : 모든 데이터를 Training data 로 사용한다. 만약, data_split_method Option을 명시 하지 않으면, 해당 Option은 auto_split으로 수행되며 auto_split은 아래와 같은 순서로 진행 된다.      1. 입력 데이터가 500개 이하라면, 모든 데이터를 Training Data로 활용 한다.      2. 입력 데이터가 500개에서 50000개 사이면 20%의 비율을 Evaluation Data로 활용한다.      3. 50000개 이상의 입력 Data의 경우 무작위로 10000개의 데이터를 나누어 Evaluation Data로 사용 된다.      data_split_method=‘auto_split’ordata_split_method=‘random’ordata_split_method=‘custom’ordata_split_method=‘seq’ordata_split_method=‘no_split’              data_split_eval_fraction      FLOAT64      이 옵션은 data_split_method Option이 ‘random’, ‘seq’ Option일 경우 사용한다. 이 Option은 평가에 사용된 데이터에 대한 소수점 값으로 해당 값은 평가에 대한 기준점역할을 한다. 기본값은 0.2      data_split_eval_fraction=0.2              data_split_col      STRING      데이터를 나누는데 기준이되는 Column을 명시하며, 선택된 컬럼은 자동으로 feature Column에서 제외 된다.  data_split_method option이 ‘custom’일 경우 해당 Option에 명시되는 Column의 타입은 Boolean이여야 한다. 이 때, Row에 해당 Column이 true나 Null값이 있을 경우, 해당 컬럼은 Evaluation Data로 사용 되고, 나머지 false인 값은 Training데이터로 사용된다. data_split_method option이 ‘seq’일 경우 해당 Column의 마지막 data_split_fraction Row (최소값에서 최대값까지)이 평가 데이터로 사용된다. 첫번째 Row는 training data로 사용된다.      data_split_col=‘col1’              ls_init_learn_rate      DOUBLE      learn_rate_strategy=‘line_search’일경우 사용하며, 이 Option은 line_rate_strategy=‘line_search’일 경우만 사용 할 수 있다.                     warm_start      BOOL      이 Option은 새로운 Training Data와 새로운 모델의 옵션, 혹은 둘다 사용 하는데 이용된다. 명시 적으로 재 정의되지 않으면 모델을 학습하는 데 사용 된 초기 옵션이 Warm start 실행에 사용됩니다. 기본값은 false.Warm start 실행에서는 반복 횟수가 0에서 시작하도록 재 설정된다. training_run No. 또는 TIMESTAMP 열은 Warm start 실행을 원래 실행과 구별하는 데 사용될 수 있다. model_type과 label Option, 그리고 Training Data의 Schema의 변경은 Warm start에서 변경 할 수 없다.             2. Prediction (예측)Prediction은 ML.PREDICT를 이용하여 예측결과를 도출 한다. 사용법은 아래와 같다.#StandardSQLSelect **predictive_label** // 예측 결과 Label \t,  \tcol1\t,\tcol2 ... From ML.PREDICT(MODEL '[MODEL_NAME]', [SQL_Statement] )다음 포스트는 실제로 사용하기 위한 예제를 포스팅 해보도록 하겠다.",
        "url": "/BigQuery-ML-Training-1"
    }
    
    
    };
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.3/lunr.min.js"></script>
<script src="assets/js/search.js"></script> -->

<form action="/search" method="get" hidden="hidden">
</form>

<script>
  (function() {
    var cx = '016653787668350288076:wlr4kwequ2m';
    var gcse = document.createElement('script');
    gcse.type = 'text/javascript';
    gcse.async = true;
    gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
    var s = document.getElementsByTagName('script')[0];
    s.parentNode.insertBefore(gcse, s);
  })();
</script>
<gcse:searchresults-only></gcse:searchresults-only>
<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.3/lunr.min.js"></script>
<script src="assets/js/search.js"></script> 
<script
    src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha256-k2WSCIexGzOj3Euiig+TlR8gA0EmPjuc79OEeY5L45g="
    crossorigin="anonymous"></script>
<script>
      function getUrlVars() // 쿼리 스트링을 파싱하는 함수
      {
        var vars = [], hash;
        var hashes = window.location.href.slice(window.location.href.indexOf('?') + 1).split('&');
        for(var i = 0; i < hashes.length; i++)
        {
          hash = hashes[i].split('=');
          vars.push(hash[0]);
          vars[hash[0]] = hash[1];
        }
        return vars;
      }
      $(document).ready(function(){ // 쿼리 스트링에서 'q'파라미터를 읽어 창 제목과 표시 제목을 바꿈
        var txt_title = "'" + decodeURIComponent(getUrlVars()['q']) + "' - 검색 결과"
        $("#page_title").text(txt_title);
        document.title = txt_title;
      });
      (function() {
        var cx = '016653787668350288076:wlr4kwequ2m';
        var gcse = document.createElement('script');
        gcse.type = 'text/javascript';
        gcse.async = true;
        gcse.src = 'https://cse.google.com/cse.js?cx=' + cx;
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(gcse, s);
      })();
    </script>
    <gcse:searchresults-only></gcse:searchresults-only> -->
            </section>

        </article>

    </div>
</main>

<!-- /post -->

<!-- The #contentFor helper here will send everything inside it up to the matching #block helper found in default.hbs -->
<script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>



        <!-- Previous/next page links - displayed on every page -->
        

        <!-- The footer at the very bottom of the screen -->
        <footer class="site-footer outer">
            <div class="site-footer-content inner">
                <section class="copyright"><a href="https://jay-pak.github.io/">To Be Continue.....</a> &copy; 2018</section>
                <section class="poweredby">Proudly published with <a href="https://jekyllrb.com/">Jekyll</a> &
                    <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a> using
                    <a href="https://github.com/jekyller/jasper2" target="_blank" rel="noopener">Jasper2</a></section>
                <nav class="site-footer-nav">
                    <a href="/">Latest Posts</a>
                    <a href="https://facebook.com/ITLimited" target="_blank" rel="noopener">Facebook</a>
                    
                    <a href="https://jay-pak.github.io/" target="_blank" rel="noopener">Jay Park</a>
                </nav>
            </div>
        </footer>

    </div>


    <!-- The big email subscribe modal content -->
    
        <div id="subscribe" class="subscribe-overlay">
            <a class="subscribe-overlay-close" href="#"></a>
            <div class="subscribe-overlay-content">
                
                <h1 class="subscribe-overlay-title">Search to To Be Continue.....</h1>
                <p class="subscribe-overlay-description">Blog 내 검색</p>
                <!-- <form method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  /><input class="location" type="hidden" name="location"  /><input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" type="email" name="email"  placeholder="youremail@example.com" />
    </div>
    <button class="" type="submit" disabled><span>Subscribe</span></button>
    <script type="text/javascript">(function(g,h,o,s,t){h[o]('.location')[s]=h[o]('.location')[s] || g.location.href;h[o]('.referrer')[s]=h[o]('.referrer')[s] || h.referrer;})(window,document,'querySelector','value');</script>
</form>
 -->
 <span id="searchform" method="post" action="/subscribe/" class="">
    <input class="confirm" type="hidden" name="confirm"  />
    <input class="location" type="hidden" name="location"  />
    <input class="referrer" type="hidden" name="referrer"  />

    <div class="form-group">
        <input class="subscribe-email" onkeyup="myFunc()" 
               id="searchtext" type="text" name="searchtext"  
               placeholder="Search..." />
    </div>
    <script type="text/javascript">
        function myFunc() {
            if(event.keyCode == 13) {
                var url = encodeURIComponent($("#searchtext").val());
                location.href = "/search.html?q=" + url;
            }
        }
    </script>
</span>
            </div>
        </div>
    
    
    <!-- highlight.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.10.0/components/prism-abap.min.js"></script>
    <script>$(document).ready(function() {
      $('pre code').each(function(i, block) {
        hljs.highlightBlock(block);
      });
    });</script>

    <!-- jQuery + Fitvids, which makes all video embeds responsive -->
    <script
        src="https://code.jquery.com/jquery-3.2.1.min.js"
        integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4="
        crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="/assets/js/jquery.fitvids.js"></script>
    <script type="text/javascript" src="https://demo.ghost.io/assets/js/jquery.fitvids.js?v=724281a32e"></script>


    <!-- Paginator increased to "infinit" in _config.yml -->
    <!-- if paginator.posts  -->
    <!-- <script>
        var maxPages = parseInt('');
    </script>
    <script src="/assets/js/infinitescroll.js"></script> -->
    <!-- /endif -->

    


    <!-- Add Google Analytics  -->
    <!-- Google Analytics Tracking code -->
 <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-125341308-1', 'auto');
  ga('send', 'pageview');

 </script>


    <!-- The #block helper will pull in data from the #contentFor other template files. In this case, there's some JavaScript which we only want to use in post.hbs, but it needs to be included down here, after jQuery has already loaded. -->
    
        <script>
$(function() {
    var $postContent = $(".post-full-content");
    $postContent.fitVids();
});
</script>

    

    <!-- Ghost outputs important scripts and data with this tag - it should always be the very last thing before the closing body tag -->
    <!-- ghost_foot -->

</body>
</html>
